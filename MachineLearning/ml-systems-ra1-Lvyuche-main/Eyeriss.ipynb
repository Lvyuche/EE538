{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uscmlsystems/ml-systems-ra1-Lvyuche/blob/main/Eyeriss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA0rETRQZBON"
      },
      "source": [
        "# EE 599 Reading Assignment 1:\n",
        "You can access paper using this [link](https://courses.cs.washington.edu/courses/cse550/21au/papers/CSE550.Eyeriss.pdf), and please do not distribute the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-HWWv6kaxrx"
      },
      "source": [
        "### Q1: (1 Point)\n",
        "\n",
        "**Disallowed** list:\n",
        "- You **MAY NOT** collaborate with anyone else on this assignment. This means you cannot talk to anyone else about the assignment until after deadline.\n",
        "- You **MAY NOT** use ChatGPT and services like that\n",
        "\n",
        "**Allowed** list:\n",
        "- Notes including any slides from the class\n",
        "- The textbooks\n",
        "- The given paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0uD-nHbHuT"
      },
      "source": [
        "### A1:\n",
        "\n",
        "I affirm I have read these exam rules and will follow them. Failure to do so may subject me to sanctions including an F in the course.\n",
        "\n",
        "**Type your full name to affirm you have read the above statement:**\n",
        "Yuxuan Lyu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNWLVCLbcjq"
      },
      "source": [
        "----\n",
        "### Q2 Summary (24 Points):\n",
        "\n",
        "Summarize the main objectives and contributions of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j5A4_Zfbpra"
      },
      "source": [
        "### A2:\n",
        "1. Main objectives:  \n",
        "    To design a kind of accelerator that can support high throughput and is power efficient for deep convolutional neural networks. Besides, it need to be compatible with models of different shapes.\n",
        "2. Contributions:   \n",
        "    1) Porposed an accelerator that can provide high parallelism for high throughput and achieve high energy efficiency by optimzing the data movements of the entire system. Besides, it is compatible with models of different shapes.   \n",
        "    2) Proposed a processing dataflow called Row Stationary, which can support a highly parallel compute paradigm and also optimize the energy cost of data movements.    \n",
        "    3) Appiled run-length compression and data gating techniques to further optimize power efficiency.     \n",
        "    4) Verified the whole system on a fabricated chip and benchmark their implementations using widely used publicly available state-of-the-art CNNs like AlexNet and VGG-16.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE2n5UQHbuZ-"
      },
      "source": [
        "---\n",
        "### Q3 Comprehension (15 Points):\n",
        "- What problem is the paper addressing?\n",
        "- How does the Eyeriss architecture differ from other architectures you are familiar with?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O7k2DbXcNp0"
      },
      "source": [
        "### A3:\n",
        "1. This paper addresses the problem that current networks have lots of parameters requiring tons of data movement on-chip and off-chip in one computation, which is more power consuming than the computation itself.\n",
        "2. To be honest, I don't really know about other architectures. But according to the paper, there are some special features. First, it has two clock domains, one is for processing and one is for off-chip DRAM communication. The two domains run independently and communicate through an asynchronous FIFO\n",
        "interface. Second, the PEs inside the Eyeriss can be divided into seperate groups for computation and can be reconfigured by config scan chain. Third, it use Row Stationay which is differ from input stationary, weight stationary and output stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnzcxvhWckY5"
      },
      "source": [
        "---\n",
        "### Q4 Technical Deep Dive (15 Points):\n",
        "- Describe the spatial architecture of Eyeriss in your own words.\n",
        "- How does the Eyeriss architecture optimize energy efficiency in dataflow for CNNs?\n",
        "- What are the main challenges in designing an energy-efficient architecture for CNNs, and how does Eyeriss tackle these challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3rFNjpcuID"
      },
      "source": [
        "### A4:\n",
        "1. First, there is two main part of the Eyeriss architecture. One I call it communication part, which mainly deal with the communication between DRAM and GLB using an asynchronous FIFO interface. Second part I call it computation part, which includes 12 * 14 PEs arranged row by row and can be separate into different groups for processing.\n",
        "2. First, it uses a proposed dataflow called Row Stationary, which can optimze filters reuse, ifmap reuse and psum accumulation. Row stationary devides convolution into 1-D primitives and mapping each primitive to one PE for processing, so the computation of each row pair stays stationary in the PE. Then each PE can use the local spads for both convolutional data reuse and psum accumulation.   \n",
        "Second, it uses a strategy called PEs Set Mapping, which make better use of the 168 PEs and data like psum and ifmap can also be share between these two sets.   \n",
        "Third, if the spad size of PE is larger enough, one PE can interleave the computation of multiple primitives which can further increase the data resue.   \n",
        "3. The main challenges is minimize data movements. Eyeriss uses Row Stationary dataflow to increase data reuse, appilies Run-Length Compression to decrease off-chip traffic and uses PEs Set mapping to further increase data reuse. Beside, it uses data gating to turn off the PE when we dont need it, for example when it input is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRBvFutTc2uh"
      },
      "source": [
        "---\n",
        "### Q5 Evaluation (15 Points):\n",
        "- What were the key results or findings of the paper? Were they compelling?\n",
        "- How do the authors validate their claims or results? Are there any weaknesses in their methodology?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKUL8nhTdNLZ"
      },
      "source": [
        "### A5:\n",
        "1. The key results is they proposed the Eyeriss, which is power-efficient by achieving multi-level data reuse and data statistics and verified it with a fabricated chip benchmark their implementations using state-of-the-art CNNs.\n",
        "Yes, they are compelling. Because power efficiency is currently a big challenges DnCNN are facing with. And the Eyeriss can be reconfigured so it is compatible with different models.\n",
        "2. Authors validate their accelerator on AlexNet and VGG-16 and measures power consumption and processing speed against established metrics. Yes, there are some weaknesses. They dont have enough comparasion between other architectures, this might result from other paper mainly test on FPGA or just using simple model. So the result might not be that direct for readers like me."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp_FV2bzdV4D"
      },
      "source": [
        "---\n",
        "### Q6 Contextual Understanding (10 Points):\n",
        "- How does this work fit into the larger context of neural network architectures and energy efficiency?\n",
        "- Can the principles of Eyeriss be applied to other deep learning architectures beyond CNNs?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvpxYhvNdg18"
      },
      "source": [
        "### A6:\n",
        "1. The Eyeriss system uses Config Scan Chain to reconfigure the PEs set mapping to adapt to different network architectures. And based on this, we should develop a even huger system to adapt to huge neural network that have more parameters than VGG-16 and AlexNet. Because the size of the CNN are incresing all the time.\n",
        "2. Yes, it can be applied. Because the mainly point of Eyeriss is to increse the data reuse, and this principles can definitely be used in other networks. Every network must have a solution to promote data reuse somehow, then it can be more power efficient somehow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxUpnGmtdjfX"
      },
      "source": [
        "---\n",
        "### Q7 Discussion and Critique (10 points):\n",
        "- Are there any assumptions made by the authors that you disagree with or find questionable?\n",
        "- Do you think there are potential improvements or future directions not addressed by the authors?\n",
        "- How would you compare Eyeriss with other architectures or solutions you know of?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjAQy1qLdvZ7"
      },
      "source": [
        "### A7:\n",
        "1. The paper does not exploit how the config scan chain are produce, I am wondering will this be too complicated for engineer to program every time they changed their model? And if we have a huge number of PEs, how can we find the best set mapping?\n",
        "2. I guess we can increase the number of PEs. Then figuring out the best PEs set mapping that can make the most of data reuse will be a challenging and improvable path.\n",
        "3. I think Eyeriss used a startionary that achieve better data reuse than other stationary, though it is more complicated. And as an architecture, I thought it is well-designed and current the best one I've ever know."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gVJ7PcKtP5lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSMCnPg8d_0S"
      },
      "source": [
        "---\n",
        "### Q8 Reflection (10 Points):\n",
        "- What was the most surprising or counterintuitive thing you learned from this paper?\n",
        "- How has reading this paper influenced your views on the importance of energy efficiency in deep learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBtgEgPXeNR5"
      },
      "source": [
        "### A8:\n",
        "1. So there is something surprised me deeply. For instance, before reading the paper, I thought when computing the convolution, PE will pass different weight value into PEs in different row, but actually PEs are the same when it is arranged, but when it is labeled, each row moves one label to the left, so the input will be passed to PEs that have the same column number. And the psum can be passed striaght down and added up, finally the result of one column will be part of the ofmao.\n",
        "2. Before I read this paper, I learned three types of stationay from lectures. But I am wondering if this kind of stationary is worthwhile for research, though we can improve data reuse, but we still need other resources instead anyway. But with the experiments and theory inside the paper, now I know that it is totally worthwhile and also it's a challenging topic."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}